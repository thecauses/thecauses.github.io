# What is Causation?

In this chapter, we discuss the the key aspects of causal inference:

1.  Define what a **treatment** and **outcome** are.
2.  Discuss the **potential outcomes** framework as a way to think about causality.
3.  Discuss the issue of **counterfactuals** as the main problem in causal inference.
4.  Discuss. the idea of **statistical inference** and **uncertainty**.

<br />

## Treatment and Outcomes

In causal inference, we are concerned with how a **treatment** (notated $D$) causes some change in the **outcome** variable (notated $Y$).

We generally assume that the treatment variable is **binary**. This means that you either get the treatment, or you do not get the treatment.

$$
D = \begin{cases}
0 \quad \text{You did not receive the treatment} \\
1 \quad \text{You did receive the treatment}
\end{cases}
$$

A few examples of causal questions include:

| Our Causal Question: $D \rightarrow Y$                                                                   | Treatment $D$                                   | Outcome $Y$                      |
|--------------------------------------|------------------|-----------------|
| How does taking the vaccine cause change in mortality rates?                                             | Getting the vaccine (yes or no)                 | Mortality rate                   |
| How does going to college change your expected lifetime earnings?                                        | Went to college (yes or no)                     | Expected lifetime earnings       |
| How does the presence of tax exemptions on electric vehicles change how many electric vehicles are sold? | Tax exemptions on electric vehicles (yes or no) | Amount of electric vehicles sold |

: {tbl-colwidths="\[50,25,25\]" .bordered}

<br />

## Potential Outcomes Framework

Imagine we have two hypothetical parallel worlds that are copies of each other. Both of these worlds are identical except for one aspect: the treatment. In one world, you get the treatment, and in the other parallel world, you do not get the treatment.

The outcome values of these two parallel worlds are called **potential outcomes**:

| Parallel World | Treatment $D$              | Potential Outcome          |
|----------------|----------------------------|----------------------------|
| 0              | Does not Receive Treatment | $\textcolor{purple}{Y(0)}$ |
| 1              | Receives Treatment         | $\textcolor{purple}{Y(1)}$ |

: {tbl-colwidths="\[25,45,30\]" .bordered}

These two hypothetical parallel worlds are identical to each other, with the only difference being that in one world, you get the treatment. Thus, any difference in outcomes between the two worlds must be the **individual treatment/causal effect** (notated $\tau$):

$$
\tau = \textcolor{purple}{Y(1)} - \textcolor{purple}{Y(0)}
$$

<br />

## The Problem of Counterfactuals

However, in reality, we do not have two parallel worlds. In the real world, someone either gets the treatment, or doesn't get the treatment. Thus, by definition, one of the potential outcomes is not observed in the real world - the one not observed is called the **counterfactual**.

| In the Real World                       | Observed Outcome $Y$           | Counterfactual          |
|------------------------------|------------------------|-------------------|
| Scenario 1: I receive treatment         | $Y = \textcolor{purple}{Y(1)}$ | $\textcolor{red}{Y(0)}$ |
| Scenario 2: I did not receive treatment | $Y = \textcolor{purple}{Y(0)}$ | $\textcolor{red}{Y(1)}$ |

: {tbl-colwidths="\[40,35,25\]" .bordered}

The **fundamental problem of causal inference** is that in order to calculate our individual treatment effect $\tau$, we need both potential outcomes. However, we can never observe both.

Causal inference is about estimating the counterfactuals with an **estimator**. This is difficult at the individual level, so instead, we focus on average treatment effects for groups:

| Type                                          | Notation      | Definition                                                                                                                                                                                               |
|------------|------------|-----------------------------------------------|
| Average Treatment Effect (ATE)                | $\tau_{ATE}$  | The average of individual treatment effects $\tau$, for all individuals in our study, including people who did and didn't get the treatment.                                                             |
| Average Treatment Effect on the Treated (ATT) | $\tau_{ATT}$  | The average of individual treatment effects $\tau$, but only for individuals who receive the treatment in our study. We ignore those who never receive treatment in our study.                           |
| Local Average Treatment Effect (LATE)         | $\tau_{LATE}$ | The average of individual treatment effects $\tau$, but only for a specific (local) group of individuals in a study. This group is usually defined by some characteristic the individuals hold together. |

: {tbl-colwidths="\[30, 15, 55\]" .bordered}

<br />

## Uncertainty and Inference

The estimation process for counterfactuals has a level of uncertainty. We cannot be sure that our estimates are completely accurate. We quantify that uncertainty in our causal effect estimates with a **standard error**. This value tells us how precise our estimates are:

-   Smaller standard errors means we are more confident about our estimates.
-   Larger standard errors means we are less certain about our estimates.

With our standard errors, we can calculate how likely that there is zero (no) causal effect (called a **p-value**). This procedure is called a hypothesis test.

-   If our p-value is less than 0.05 (5%), there is less than a 5% chance that there is zero causal effect, which implies 95%+ chance there is a causal effect. In this case, we say there is a **statistically significant causal effect**.
-   If our p-value is larger than 0.05 (5%), there is a greater than 5% chance that the causal effect is 0. We generally conclude that there is no statistically significant causal effect.

In most software and reports, if there is a p-value less than 5%, the authors will put stars (\*\*) next to the estimate. If you see any stars, there is statistically significant causal effect.

![](images/clipboard-3174072485.png){fig-align="center" width="50%"}

In the figure above, you can see the stars \*\*\* indicate a non-zero causal effect. Do not worry about interpreting the table now - we will show more details in the following chapters.

<br />
