# What is Causation?

::: {.callout-tip appearance="simple"}
## Overview

In this chapter, we discuss the the key aspects of causal inference:

1.  Define what a **treatment** and **outcome** are.
2.  Discuss the **potential outcomes** framework as a way to think about causality.
3.  Discuss the issue of **counterfactuals** as the main problem in causal inference.
4.  Discuss. the idea of **statistical inference** and **uncertainty**.
:::

<br />

## Treatment and Outcomes

In causal inference, we are concerned with how a **treatment** (notated $D$) causes some change in the **outcome** variable (notated $Y$).

We generally assume that the treatment variable is **binary**. This means that you either get the treatment, or you do not get the treatment.

$$
D = \begin{cases}
0 \quad \text{You did not receive the treatment} \\
1 \quad \text{You did receive the treatment}
\end{cases}
$$

A few examples of causal questions include:

| Our Causal Question: $D \rightarrow Y$                                                                   | Treatment $D$                                   | Outcome $Y$                      |
|------------------------------------|------------------|------------------|
| How does taking the vaccine cause change in mortality rates?                                             | Getting the vaccine (yes or no)                 | Mortality rate                   |
| How does going to college change your expected lifetime earnings?                                        | Went to college (yes or no)                     | Expected lifetime earnings       |
| How does the presence of tax exemptions on electric vehicles change how many electric vehicles are sold? | Tax exemptions on electric vehicles (yes or no) | Amount of electric vehicles sold |

: {tbl-colwidths="\[50,25,25\]" .bordered}

<br />

## Potential Outcomes Framework

We want to find the causal effect of a treatment on an outcome. But what is a causal effect?

Imagine we have two hypothetical parallel worlds that are copies of each other. Both of these worlds are identical except for one aspect: the treatment. In one world, you get the treatment, and in the other parallel world, you do not get the treatment.

The outcome values of these two parallel worlds are called **potential outcomes**:

| Parallel World | Treatment $D$              | Potential Outcome          |
|----------------|----------------------------|----------------------------|
| 0              | Does not Receive Treatment | $\textcolor{purple}{Y(0)}$ |
| 1              | Receives Treatment         | $\textcolor{purple}{Y(1)}$ |

: {tbl-colwidths="\[25,45,30\]" .bordered}

These two hypothetical parallel worlds are identical to each other, with the only difference being that in one world, you get the treatment. Thus, any difference in your potential outcomes must be the treatment effect.

::: {.callout-important appearance="simple"}
## Key Definition: Individual Treatment Effect

The individual treatment effect (notated $\tau$) is the causal effect of a treatment on an outcome for a specific individual:

$$
\tau = \textcolor{purple}{Y(1)} - \textcolor{purple}{Y(0)}
$$
:::

As the name implies, this is an individual effect, that belongs to an individual within our study. We typically have multiple individuals in a study.

-   If every individual in our study has the same individual treatment effect $\tau$, we have a **homogenous** treatment effect.
-   If individual's have different treatment effects $\tau$, we have a **heterogenous** effect.

::: {.callout-note collapse="true" appearance="simple"}
## Additional Info: SUTVA

The potential outcomes framework described above, with two parallel worlds, depends on a key assumption, called the stable unit treatment value assumption (SUTVA).

Let us say we have multiple people in our study, including person A and B. SUTVA essentially says that if person A gets the treatment, that does not affect the outcome values of person B.

The reason this is important is that if A's treatment status affects B's outcome, then we would have more than 2 potential worlds - not just B getting the treatment or not, but also if A got the treatment or not. Common causes of SUTVA violations include:

-   Spill-over effects. For example, if we are testing a new curriculum's impact on student performance, student A who got the new curriculum might teach/tutor their friend, student B, which affects their outcomes.
-   Dilution: For example, in vaccines, there is herd immunity. That mean other people getting the vaccines improves my health outcomes.
:::

<br />

## The Problem of Counterfactuals

However, in reality, we do not have two parallel worlds. In the real world, someone either gets the treatment, or doesn't get the treatment. Thus, by definition, one of the potential outcomes is not observed in the real world - the one not observed is called the **counterfactual**.

| In the Real World                       | Observed Outcome $Y$           | Counterfactual          |
|-------------------------|------------------------|------------------------|
| Scenario 1: I receive treatment         | $Y = \textcolor{purple}{Y(1)}$ | $\textcolor{red}{Y(0)}$ |
| Scenario 2: I did not receive treatment | $Y = \textcolor{purple}{Y(0)}$ | $\textcolor{red}{Y(1)}$ |

: {tbl-colwidths="\[40,35,25\]" .bordered}

Remember our individual treatment effect $\tau$:

$$
\tau = \textcolor{purple}{Y(1)} - \textcolor{purple}{Y(0)}
$$

The **fundamental problem of causal inference** is that in order to calculate our treatment effect $\tau$, we need both potential outcomes. However, we can never observe both.

Causal inference is about estimating the counterfactuals with an **estimator**. This is difficult at the individual level, so instead, we focus on average treatment effects for groups:

| Type                                          | Notation      | Definition                                                                                                                                                                                               |
|---------------|---------------|-------------------------------------------|
| Average Treatment Effect (ATE)                | $\tau_{ATE}$  | The average of individual treatment effects $\tau$, for all individuals in our study, including people who did and didn't get the treatment.                                                             |
| Average Treatment Effect on the Treated (ATT) | $\tau_{ATT}$  | The average of individual treatment effects $\tau$, but only for individuals who receive the treatment in our study. We ignore those who never receive treatment in our study.                           |
| Local Average Treatment Effect (LATE)         | $\tau_{LATE}$ | The average of individual treatment effects $\tau$, but only for a specific (local) group of individuals in a study. This group is usually defined by some characteristic the individuals hold together. |

: {tbl-colwidths="\[30, 15, 55\]" .bordered}

<br />

## Uncertainty and Inference

The estimation process for counterfactuals has a level of uncertainty. We cannot be sure that our estimates are completely accurate. We quantify that uncertainty in our causal effect estimates with a **standard error**. This value tells us how precise our estimates are:

-   Smaller standard errors means we are more confident about our estimates.
-   Larger standard errors means we are less certain about our estimates.

With our standard errors, we can calculate how likely that there is zero (no) causal effect (called a **p-value**). This procedure is called a hypothesis test.

-   If our p-value is less than 0.05 (5%), there is less than a 5% chance that there is zero causal effect, which implies 95%+ chance there is a causal effect. In this case, we say there is a **statistically significant causal effect**.
-   If our p-value is larger than 0.05 (5%), there is a greater than 5% chance that the causal effect is 0. We generally conclude that there is no statistically significant causal effect.

In most software and reports, if there is a p-value less than 5%, the authors will put stars (\*\*) next to the estimate. If you see any stars, there is statistically significant causal effect.

![](images/clipboard-3174072485.png){fig-align="center" width="50%"}

In the figure above, you can see the stars \*\*\* indicate a non-zero causal effect. Do not worry about interpreting the table now - we will show more details in the following chapters.
